import copy
import json
import multiprocessing
import os
import os.path as osp
import pickle
import sys
import zlib

import numpy as np
from tqdm import tqdm


CPU_COUNT = multiprocessing.cpu_count()


def print_progress(iteration, total, prefix='', suffix='', decimals=1, bar_length=100):
    """
    Call in a loop to create terminal progress bar

    Args:
        iteration   - Required  : current iteration (Int)
        total       - Required  : total iterations (Int)
        prefix      - Optional  : prefix string (Str)
        suffix      - Optional  : suffix string (Str)
        decimals    - Optional  : positive number of decimals in percent complete (Int)
        bar_length  - Optional  : character length of bar (Int)
    """

    format_str = "{0:." + str(decimals) + "f}"
    percents = format_str.format(100 * (iteration / float(total)))
    filledLength = int(round(bar_length * iteration / float(total)))
    bar = '' * filledLength + '-' * (bar_length - filledLength)
    sys.stdout.write('\r%s |%s| %s%s %s' %
                     (prefix, bar, percents, '%', suffix)),
    if iteration == total:
        sys.stdout.write('\x1b[2K\r')
    sys.stdout.flush()


def save_seq_and_constellation_data(item, sequence_data_dir, constellation_data_dir):
    # Save sequence data of In-phase/Quadrature
    iq_dir = osp.join(sequence_data_dir, 'iq')
    if not osp.isdir(iq_dir):
        os.makedirs(iq_dir)
    iq_path = osp.join(iq_dir, item['file_name'])
    np.save(iq_path, item['data'])

    # Save sequence data of Amplitude/Phase
    ap_dir = osp.join(sequence_data_dir, 'ap')
    if not osp.isdir(ap_dir):
        os.makedirs(ap_dir)
    ap_path = osp.join(ap_dir, item['file_name'])
    data = item['data'][0, :] + 1j * item['data'][1, :]
    amplitude = np.abs(data)
    phase = np.angle(data)
    ap_data = np.vstack((amplitude, phase))
    np.save(ap_path, ap_data)

    # Save constellation data generated by different method parameters
    item_data = item['data']
    item_data[0, :] = item_data[0, :] / item['real_scale']
    item_data[1, :] = item_data[1, :] / item['imag_scale']
    constellations, filters = Constellation().generate_by_filter(item_data)

    for constellation, param in zip(constellations, filters):
        constellation_dir = osp.join(constellation_data_dir,
                                     'filter_size_{:<.3f}_stride_{:<.3f}'.format(param[0], param[1]))
        if not osp.isdir(constellation_dir):
            os.makedirs(constellation_dir)
        constellation_path = osp.join(constellation_dir, item['file_name'])
        np.save(constellation_path, constellation)


def save_seq(item, sequence_data_dir):
    # Save sequence data of In-phase/Quadrature
    iq_dir = osp.join(sequence_data_dir, 'iq')
    if not osp.isdir(iq_dir):
        os.makedirs(iq_dir)
    iq_path = osp.join(iq_dir, item['file_name'])
    np.save(iq_path, item['data'])


def combine_two_infos(annotations1, annotations2):
    combine_annotation = copy.deepcopy(annotations1)
    update_list = ['annotations']
    for key_name in update_list:
        combine_annotation[key_name].extend(copy.deepcopy(annotations2[key_name]))

    return combine_annotation


class Constellation:
    def __init__(self, filter_size=None, filter_stride=None):
        # matrix window performance_info
        self.height_range = [-1, 1]
        self.width_range = [-1, 1]

        # parameters for converting sequence
        # data (2, N) to constellation matrix based on conv mode
        if filter_size is None:
            self.filter_size = [0.05, 0.02]
        else:
            self.filter_size = filter_size
        if filter_stride is None:
            self.filter_stride = [0.05, 0.02]
        else:
            self.filter_stride = filter_stride

    def get_filters(self):
        filters = []
        for filter_size, filter_stride in zip(self.filter_size, self.filter_stride):
            filters.append([filter_size, filter_stride])

        return filters

    def generate_by_filter(self, data):

        constellations = []
        filters = []
        for filter_size, filter_stride in zip(self.filter_size, self.filter_stride):
            matrix_width = int((self.width_range[1] - self.width_range[0] - filter_size) / filter_stride + 1)
            matrix_height = int((self.height_range[1] - self.height_range[0] - filter_size) / filter_stride + 1)

            constellation = np.zeros((matrix_height, matrix_width))

            def axis_is(query_axis_x, query_axis_y):
                axis_x = query_axis_x // filter_stride
                axis_y = query_axis_y // filter_stride
                if axis_x * filter_stride + filter_size < query_axis_x:
                    position = [None, None]
                elif axis_y * filter_stride + filter_size < query_axis_y:
                    position = [None, None]
                else:
                    position = [int(axis_x), int(axis_y)]
                return position

            pos_list = map(axis_is, list(data[0, :]), list(data[1, :]))
            num_point = 0
            for pos in pos_list:
                if pos[0] is not None:
                    constellation[pos[0], pos[1]] += 1
                    num_point += 1
            constellations.append(constellation / num_point)
            filters.append([filter_size, filter_stride])

        return constellations, filters


class BaseDataset:

    def __init__(self, organization, root_dir, version, data_ratios):
        self.organization = organization
        self.root_dir = root_dir
        self.version = version
        self.data_dir = osp.join(self.root_dir, self.organization, self.version)
        self.train_num = 0
        self.val_num = 0
        self.test_num = 0
        self.data_ratios = data_ratios
        self.data_name = ''
        co = Constellation()
        self.filters = co.get_filters()
        self.filter_config = [[0.02, 0.02], [0.05, 0.05]]

    def preprocess_original_data(self):
        dataset = []
        infos = []

        return dataset, infos

    def generate(self):
        try:
            dataset, infos = self.preprocess_original_data()
            sequence_data_dir = osp.join(self.data_dir, 'sequence_data')
            constellation_data_dir = osp.join(
                self.data_dir, 'constellation_data')

            if not osp.isdir(sequence_data_dir):
                os.makedirs(sequence_data_dir)

            if not osp.isdir(constellation_data_dir):
                os.makedirs(constellation_data_dir)

            # Save the item as *.npy file
            # num_items = len(dataset)
            # with futures.ProcessPoolExecutor(max_workers=CPU_COUNT) as executor:
            #     fs = [executor.submit(save_seq_and_constellation_data, item, sequence_data_dir,
            #                           constellation_data_dir)
            #           for item in dataset]
            #     for i, f in enumerate(futures.as_completed(fs)):
            #         # Write progress to error so that it can be seen
            #         print_progress(i, num_items, prefix='Convert {}-{}'.format(self.organization, self.version),
            #                        suffix='Done ',
            #                        bar_length=40)

            for item in tqdm(dataset):
                save_seq_and_constellation_data(item, sequence_data_dir, constellation_data_dir)

            for set_name in infos:
                self._generate(set_name, infos[set_name])

        except Exception as e:
            print('Error Message is: {}'.format(e))
            raise RuntimeError(
                'Converting data {}-{} failed'.format(self.organization, self.version))

    def _generate(self, set_name, set_info):
        print(f'\nSave {set_name} annotation json for the data set {self.version} generated by {self.organization}')
        json.dump(set_info, open(self.data_dir + f'/{set_name}.json', 'w'), indent=4, sort_keys=True)
        print(f'Cache {set_name} data in dataset {self.data_name}!')
        cache_data = {'sequence_data/ap': {'data': [], 'shape': None, 'dtype': None},
                      'sequence_data/iq': {'data': [], 'shape': None, 'dtype': None},
                      'constellation_data/filter_size_0.020_stride_0.020': {'data': [], 'shape': None, 'dtype': None},
                      'constellation_data/filter_size_0.050_stride_0.050': {'data': [], 'shape': None, 'dtype': None},
                      }
        file_name_index = dict()
        idx = 0
        for annotation in tqdm(set_info['annotations']):
            file_name = annotation['file_name']
            for key in cache_data:
                file_path = osp.join(self.data_dir, key, file_name)
                data = np.load(file_path)
                data = data.astype(np.float32)
                cache_data[key]['shape'] = data.shape
                cache_data[key]['dtype'] = data.dtype
                # it's not beneficial to compress sequence data
                if 'sequence_data' in key:
                    data = np.expand_dims(data, axis=0)
                    cache_data[key]['data'].append(data)
                else:
                    cdata = zlib.compress(data.tobytes())
                    cache_data[key]['data'].append(cdata)
            file_name_index[file_name] = idx
            idx += 1

        for key in cache_data:
            if 'sequence_data' in key:
                cache_data[key]['data'] = np.concatenate(cache_data[key]['data'], axis=0)
            cache_data[key]['lookup_table'] = file_name_index

        cache_dir = osp.join(self.data_dir, 'cache')
        if not osp.isdir(cache_dir):
            os.makedirs(cache_dir)

        for key in cache_data:
            cache_name = key.split('/')[-1]
            cache_file_path = osp.join(cache_dir, set_name + '_' + cache_name + '.pkl')
            pickle.dump(cache_data[key], open(cache_file_path, 'wb'), protocol=4)
